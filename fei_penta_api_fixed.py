from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from geb_1_3b.modeling_geblm import GEBLMForCausalLM
import datetime
import os

# --- Configura√ß√£o do FastAPI ---
app = FastAPI(title="Fei PENTA API Fake Realista")

# --- Modelo de request ---
class PromptRequest(BaseModel):
    prompt: str
    max_length: int = 100
    temperature: float = 1.0

# --- Inicializa√ß√£o do modelo fake ---
MODEL_NAME = "GEB-AGI/geb-1.3b"
device = "cpu"

print("üîπ Carregando modelo e tokenizer...")
model = GEBLMForCausalLM.from_pretrained(MODEL_NAME, trust_remote_code=True)
model.to(device)
print("‚úÖ Modelo carregado (fake)")

# --- Diret√≥rio e arquivo de log ---
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)
LOG_FILE = os.path.join(LOG_DIR, "acquisitions.log")

def log_acquisition(prompt: str, response: str):
    """Registra cada prompt e resposta com timestamp"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_line = f"[{timestamp}] PROMPT: {prompt} | RESPONSE: {response}\n"
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(log_line)
    print(log_line, end="")  # Tamb√©m exibe no terminal

# --- Fun√ß√£o de gera√ß√£o de resposta fake mais realista ---
def generate_response(prompt: str, max_length: int = 100, temperature: float = 1.0):
    prompt_lower = prompt.lower()
    if "ol√°" in prompt_lower:
        response = "Ol√°! Como posso ajudar voc√™ hoje?"
    elif "ajuda" in prompt_lower:
        response = "Claro! Estou aqui para te auxiliar."
    elif "teste" in prompt_lower:
        response = "Este √© um teste do modelo fake. Tudo funcionando!"
    else:
        response = f"[RESPOSTA SIMULADA] Prompt: {prompt}, max_length: {max_length}, temperature: {temperature}"
    return response

# --- Endpoint principal ---
@app.post("/generate")
async def generate_text(request: PromptRequest):
    prompt = request.prompt
    if not prompt:
        raise HTTPException(status_code=400, detail="Prompt n√£o pode ser vazio")

    response = generate_response(prompt, request.max_length, request.temperature)

    # Log de aquisi√ß√£o
    log_acquisition(prompt, response)

    return {
        "prompt": prompt,
        "response": response,
        "max_length": request.max_length,
        "temperature": request.temperature
    }

# --- Root endpoint para teste r√°pido ---
@app.get("/")
async def root():
    return {"message": "API Fei PENTA rodando com modelo fake realista!"}
